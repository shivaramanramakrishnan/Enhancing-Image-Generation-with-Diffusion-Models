{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/tigershiva02/dl-project-enhancing-image-generation?scriptVersionId=208336405\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"pip install lpips\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import transforms, datasets\nfrom torchvision.utils import save_image\nfrom tqdm import tqdm\nfrom math import log10\nfrom torch.cuda.amp import GradScaler, autocast\nimport matplotlib.pyplot as plt\n\n# Enable optimized CUDA kernels\nimport torch.backends.cudnn as cudnn\ncudnn.benchmark = True\n\n# Check device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Dataset Preprocessing\nIMG_SIZE = 32  # Reduced resolution to save memory\nBATCH_SIZE = 8  # Reduced batch size\nDATASET_DIR = \"/kaggle/input/celeba-dataset/img_align_celeba\"  # Update path if necessary\n\ntransform = transforms.Compose([\n    transforms.CenterCrop(178),\n    transforms.Resize(IMG_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])  # Normalize to [-1, 1]\n])\n\ndataset = datasets.ImageFolder(root=DATASET_DIR, transform=transform)\n\n# Use a smaller dataset subset\nsubset_size = 5000  # Further reduced dataset size\nindices = torch.randperm(len(dataset))[:subset_size]\ndataset = Subset(dataset, indices)\n\ndataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n\n# Define U-Net\nclass UNet(nn.Module):\n    def __init__(self):\n        super(UNet, self).__init__()\n        \n        # Encoder\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n        )\n\n        # Middle Layers\n        self.middle = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n            nn.ReLU(),\n        )\n\n        # Decoder\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n            nn.Tanh(),\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.middle(x)\n        x = self.decoder(x)\n        assert x.shape[-2:] == (IMG_SIZE, IMG_SIZE), f\"Output shape mismatch: {x.shape}\"\n        return x\n\nmodel = UNet().to(device)\n\n# Training Setup\noptimizer = Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = StepLR(optimizer, step_size=10, gamma=0.5)\ncriterion_mse = nn.MSELoss()\nscaler = GradScaler()  # For mixed precision training\nEPOCHS = 50\n\n\n# PSNR Calculation Function\ndef calculate_psnr(original, generated):\n    mse = torch.mean((original - generated) ** 2)\n    if mse == 0:\n        return 100  # No difference\n    psnr = 10 * log10(1 / mse.item())\n    return psnr\n\n# Pixel Accuracy Function\ndef pixel_accuracy(original, generated, threshold=0.1):\n    return torch.mean((torch.abs(original - generated) < threshold).float()).item()\n\n# Metrics Storage\nloss_history = []\npsnr_history = []\naccuracy_history = []\n\nfor epoch in range(EPOCHS):\n    model.train()\n    running_loss = 0.0\n    psnr_total = 0.0\n    accuracy_total = 0.0  # Initialize accuracy tracker\n\n    for images, _ in tqdm(dataloader):\n        images = images.to(device)\n\n        # Adding noise\n        noise = torch.randn_like(images) * 0.1\n        noisy_images = images + noise.to(device)\n        noisy_images = torch.clip(noisy_images, -1, 1)\n\n        with autocast():  # Mixed precision context\n            # Forward pass\n            outputs = model(noisy_images)\n\n            # Compute loss\n            mse_loss = criterion_mse(outputs, images)\n            total_loss = mse_loss\n\n        # Backpropagation\n        optimizer.zero_grad()\n        scaler.scale(total_loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        running_loss += total_loss.item()\n\n        # Calculate PSNR and Accuracy for the batch\n        psnr_total += calculate_psnr(images, outputs)\n        accuracy_total += pixel_accuracy(images, outputs)\n\n        # Clear unused memory\n        torch.cuda.empty_cache()\n\n    # Store average metrics\n    avg_loss = running_loss / len(dataloader)\n    avg_psnr = psnr_total / len(dataloader)\n    avg_accuracy = accuracy_total / len(dataloader)  # Average accuracy\n\n    loss_history.append(avg_loss)\n    psnr_history.append(avg_psnr)\n    accuracy_history.append(avg_accuracy)\n\n    scheduler.step()\n    print(f\"Epoch [{epoch + 1}/{EPOCHS}], Loss: {avg_loss:.4f}, PSNR: {avg_psnr:.2f} dB, Accuracy: {avg_accuracy * 100:.2f}%\")\n\n# Plotting Results\ndef plot_results(loss_history, psnr_history):\n    plt.figure(figsize=(10, 5))\n\n    # Plot Training Loss\n    plt.subplot(1, 2, 1)\n    plt.plot(loss_history, label='Training Loss')\n    plt.title(\"Training Loss Over Epochs\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n\n    # Plot PSNR\n    plt.subplot(1, 2, 2)\n    plt.plot(psnr_history, label='PSNR (dB)', color='orange')\n    plt.title(\"PSNR Over Epochs\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"PSNR (dB)\")\n    plt.legend()\n\n    # Accuracy\n    plt.subplot(1, 3, 3)\n    plt.plot(accuracy_history, label=\"Pixel Accuracy (%)\", color=\"green\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy (%)\")\n    plt.title(\"Pixel Accuracy Over Epochs\")\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n# Call the function to plot results\nplot_results(loss_history, psnr_history)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T02:42:18.641797Z","iopub.execute_input":"2024-11-19T02:42:18.642166Z","iopub.status.idle":"2024-11-19T02:53:07.854123Z","shell.execute_reply.started":"2024-11-19T02:42:18.642137Z","shell.execute_reply":"2024-11-19T02:53:07.853218Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}